{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import itertools as it\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class data_object(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_states_3.pickle','rb') as f:\n",
    "    random_states = pickle.load(f)\n",
    "random_states = {i:random_states[i] for i in random_states}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, let's take a look at solution statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs = []\n",
    "finished_initialization = []\n",
    "finished_DDF_product = []\n",
    "finished_revenue = []\n",
    "finished_DDF_reflux = []\n",
    "finished_profit_3 = []\n",
    "finished_profit_3_1 = []\n",
    "finished_profit_3_2 = []\n",
    "\n",
    "with open('./log/master/master_log.txt','r') as f:\n",
    "    for key, group in it.groupby(f,lambda line: line.startswith('------------')):\n",
    "        if not key:\n",
    "            run_data = list(group)\n",
    "\n",
    "            # get run number\n",
    "            start = 'Preset_Case_'\n",
    "            end = '_'\n",
    "            s = run_data[2]\n",
    "            run_case = int(s[s.find(start)+len(start):s.rfind(end)])\n",
    "            total_runs.append(run_case)\n",
    "            \n",
    "            # get status\n",
    "            if 'Success: > Initialization\\n' in run_data:\n",
    "                finished_initialization.append(True)\n",
    "            else:\n",
    "                finished_initialization.append(False)\n",
    "                \n",
    "            if 'Success: > Added DDF formulation - Product\\n' in run_data:\n",
    "                finished_DDF_product.append(True)\n",
    "            else:\n",
    "                finished_DDF_product.append(False)\n",
    "                \n",
    "            if 'Success: > One-step Optimization - Revenue\\n' in run_data:\n",
    "                finished_revenue.append(True)\n",
    "            else:\n",
    "                finished_revenue.append(False)\n",
    "                \n",
    "            if 'Success: > Added DDF formulation - Reflux\\n' in run_data:\n",
    "                finished_DDF_reflux.append(True)\n",
    "            else:\n",
    "                finished_DDF_reflux.append(False)\n",
    "                \n",
    "            if 'Success: > One-step Optimization - Profit 3\\n' in run_data:\n",
    "                finished_profit_3.append(True)\n",
    "            else:\n",
    "                finished_profit_3.append(False)\n",
    "            \n",
    "            if 'Success: > One-step Optimization - Profit 3-1\\n' in run_data:\n",
    "                finished_profit_3_1.append(True)\n",
    "            else:\n",
    "                finished_profit_3_1.append(False)\n",
    "                \n",
    "            if 'Success: > One-step Optimization - Profit 3-2\\n' in run_data:\n",
    "                finished_profit_3_2.append(True)\n",
    "            else:\n",
    "                finished_profit_3_2.append(False)\n",
    "                \n",
    "finished_initialization = np.array(finished_initialization)\n",
    "finished_DDF_product = np.array(finished_DDF_product)\n",
    "finished_revenue = np.array(finished_revenue)\n",
    "finished_DDF_reflux = np.array(finished_DDF_reflux)\n",
    "finished_profit_3 = np.array(finished_profit_3)\n",
    "finished_profit_3_1 = np.array(finished_profit_3_1)\n",
    "finished_profit_3_2 = np.array(finished_profit_3_2)\n",
    "\n",
    "finished_optimization_any = np.any([finished_revenue,finished_profit_3,finished_profit_3_1,finished_profit_3_2],axis=0)\n",
    "finished_optimization_all = np.all([finished_revenue,finished_profit_3,finished_profit_3_1,finished_profit_3_2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization_failure_case = [total_runs[j_] for j_, j in enumerate(finished_initialization) if not j]\n",
    "DDF_product_failure_case = [total_runs[j_] for j_, j in enumerate(finished_DDF_product) if not j]\n",
    "revenue_failure_case = [total_runs[j_] for j_, j in enumerate(finished_revenue) if not j]\n",
    "DDF_reflux_failure_case = [total_runs[j_] for j_, j in enumerate(finished_DDF_reflux) if not j]\n",
    "profit_3_failure_case = [total_runs[j_] for j_, j in enumerate(finished_profit_3) if not j]\n",
    "profit_3_1_failure_case = [total_runs[j_] for j_, j in enumerate(finished_profit_3_1) if not j]\n",
    "profit_3_2_failure_case = [total_runs[j_] for j_, j in enumerate(finished_profit_3_2) if not j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('invalid cases: ', {591, 809, 893, 967, 996})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'invalid cases: ', set(i for i in random_states) - set(total_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successfully initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 0.9035175879396985)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finished_initialization), sum(finished_initialization) / len(total_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successfully adopted product DDF formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 0.978865406006674)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finished_DDF_product), sum(finished_DDF_product) / sum(finished_initialization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successfully reached revenue optimum solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 0.6409090909090909)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finished_revenue), sum(finished_revenue) / sum(finished_DDF_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successfully adopted reflux DDF formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finished_DDF_reflux), sum(finished_DDF_reflux) / sum(finished_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successfully reached profit optimum solution: profit-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(562, 0.9964539007092199)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finished_profit_3), sum(finished_profit_3) / sum(finished_DDF_reflux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing tray cost weight : profit-3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 0.975177304964539)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finished_profit_3_1), sum(finished_profit_3_1) / sum(finished_DDF_reflux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing feed cost weight: profit-3-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552, 0.9787234042553191)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(finished_profit_3_2), sum(finished_profit_3_2) / sum(finished_DDF_reflux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different starting points doesn't seem to drastically affect success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(x):\n",
    "    x = np.array(x)\n",
    "    return x, x[finished_initialization], x[finished_optimization_any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reflux_ratio_all = np.array([random_states[i].rr_ratio for i in random_states if i in total_runs])\n",
    "intermediate_location_all = np.array([sorted(random_states[i].side_draw_flag.keys())[0] for i in random_states if i in total_runs])\n",
    "intermediate_draw_all = np.array([list(random_states[i].side_draw_flag.values())[0] for i in random_states if i in total_runs])\n",
    "gasoline_location_all = np.array([sorted(random_states[i].side_draw_flag.keys())[1] for i in random_states if i in total_runs])\n",
    "gasoline_draw_all = np.array([list(random_states[i].side_draw_flag.values())[1] for i in random_states if i in total_runs])\n",
    "diesel_location_all = np.array([sorted(random_states[i].side_draw_flag.keys())[2] for i in random_states if i in total_runs])\n",
    "diesel_draw_all = np.array([list(random_states[i].side_draw_flag.values())[2] for i in random_states if i in total_runs])\n",
    "\n",
    "fig, axs = plt.subplots(7,1,figsize=(16,14))\n",
    "\n",
    "tmp_dic = {0:(reflux_ratio_all,'Reflux',(0.05,0.15),10),\n",
    "          1:(intermediate_location_all,'Heavy naphtha Tray',(1,2),2),\n",
    "          2:(intermediate_draw_all,'Heavy naphtha Draw',(0.01,0.03),10),\n",
    "          3:(gasoline_location_all,'Gasoline Tray',(3,9),7),\n",
    "          4:(gasoline_draw_all,'Gasoline Draw',(0.1,0.3),10),\n",
    "          5:(diesel_location_all,'Diesel Tray',(10,18),9),\n",
    "          6:(diesel_draw_all,'Diesel Draw',(0.2,0.5),10)}\n",
    "\n",
    "for j in range(7):\n",
    "    y, bins, patches = axs[j].hist((divide_data(tmp_dic[j][0])),bins=tmp_dic[j][3],histtype='bar',range=tmp_dic[j][2],alpha=0.7)\n",
    "    ymax = max(y[0])\n",
    "    axs[j].set_ylim(bottom=0,top=2*ymax)\n",
    "\n",
    "    bincenters = 0.5*(bins[1:]+bins[:-1])\n",
    "    ratio_init = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[1],y[0])]\n",
    "    ratio_opt = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[2],y[1])]\n",
    "\n",
    "    ax_ = plt.twinx(axs[j])\n",
    "    ax_.plot(bincenters,ratio_init,'C1:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    ax_.plot(bincenters,ratio_opt,'C2:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    ax_.set_ylim(0,1.2)\n",
    "\n",
    "    # ax.grid()\n",
    "    axs[j].set_title(tmp_dic[j][1])\n",
    "\n",
    "fig.legend(['Set-Point','Initialization','Optimized'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactive_stages = random_states[1].temperature_flag.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_all = {j:np.array([random_states[i].temperature_flag[j] for i in random_states if i in total_runs])\\\n",
    "                   for j in reactive_stages}\n",
    "\n",
    "fig, axs = plt.subplots(len(reactive_stages),2,figsize=(16,14))\n",
    "\n",
    "for j_, j in enumerate(reactive_stages):\n",
    "    y, bins, patches = axs[j_][0].hist(divide_data(temperature_all[j]),bins=10,histtype='bar',range=(220,280),alpha=0.7)\n",
    "    ymax = max(y[0])\n",
    "    # ax.set_ylim(bottom=0,top=2*ymax)\n",
    "\n",
    "    bincenters = 0.5*(bins[1:]+bins[:-1])\n",
    "    ratio_init = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[1],y[0])]\n",
    "    ratio_opt = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[2],y[1])]\n",
    "\n",
    "    axs[j_][1].plot(bincenters,ratio_init,'C1:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    axs[j_][1].plot(bincenters,ratio_opt,'C2:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    axs[j_][1].set_ylim(0,1.2)\n",
    "    axs[j_][1].set_xlim(220,280)\n",
    "\n",
    "axs[0][0].set_title('Temperature')\n",
    "axs[0][0].legend(['Set-Point','Initialization','Optimization'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strong 1-sided start seems to increase success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "catalyst_all = {j:np.array([random_states[i].catalyst_flag[j] for i in random_states if i in total_runs])\\\n",
    "                   for j in reactive_stages}\n",
    "\n",
    "fig, axs = plt.subplots(len(reactive_stages),2,figsize=(16,14))\n",
    "\n",
    "for j_, j in enumerate(reactive_stages):\n",
    "    y, bins, patches = axs[j_][0].hist(divide_data(catalyst_all[j]),bins=10,histtype='bar',range=(0,8000),alpha=0.7)\n",
    "    ymax = max(y[0])\n",
    "    # ax.set_ylim(bottom=0,top=2*ymax)\n",
    "\n",
    "    bincenters = 0.5*(bins[1:]+bins[:-1])\n",
    "    ratio_init = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[1],y[0])]\n",
    "    ratio_opt = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[2],y[1])]\n",
    "\n",
    "    axs[j_][1].plot(bincenters,ratio_init,'C1:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    axs[j_][1].plot(bincenters,ratio_opt,'C2:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    axs[j_][1].set_ylim(0,1.2)\n",
    "    axs[j_][1].set_xlim(0,8000)\n",
    "\n",
    "axs[0][0].set_title('catalyst')\n",
    "axs[0][0].legend(['Set-Point','Initialization','Optimization'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_all = {j:np.array([random_states[i].feed_flag[j] for i in random_states if i in total_runs])\\\n",
    "                   for j in reactive_stages}\n",
    "\n",
    "fig, axs = plt.subplots(len(reactive_stages),2,figsize=(16,14))\n",
    "\n",
    "for j_, j in enumerate(reactive_stages):\n",
    "    y, bins, patches = axs[j_][0].hist(divide_data(feed_all[j]),bins=10,histtype='bar',range=(0,3),alpha=0.7)\n",
    "    ymax = max(y[0])\n",
    "    # ax.set_ylim(bottom=0,top=2*ymax)\n",
    "\n",
    "    bincenters = 0.5*(bins[1:]+bins[:-1])\n",
    "    ratio_init = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[1],y[0])]\n",
    "    ratio_opt = [float('nan') if j==0 or i==0 else i/j for i,j in zip(y[2],y[1])]\n",
    "\n",
    "    axs[j_][1].plot(bincenters,ratio_init,'C1:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    axs[j_][1].plot(bincenters,ratio_opt,'C2:o',markeredgecolor='w',markersize=12,markeredgewidth = 1)\n",
    "    axs[j_][1].set_ylim(0,1.2)\n",
    "    axs[j_][1].set_xlim(0,3)\n",
    "\n",
    "axs[0][0].set_title('feed')\n",
    "axs[0][0].legend(['Set-Point','Initialization','Optimization'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce dimension for visulization using PCA, uniform distribution, expect to yield little capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.stack((\n",
    "    reflux_ratio_all,\n",
    "    intermediate_location_all,\n",
    "    intermediate_draw_all,\n",
    "    gasoline_location_all,\n",
    "    gasoline_draw_all,\n",
    "    diesel_location_all,\n",
    "    diesel_draw_all,\n",
    "    *[temperature_all[j] for j in temperature_all],\n",
    "    *[catalyst_all[j] for j in temperature_all],\n",
    "    *[feed_all[j] for j in temperature_all]\n",
    "),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_scaled = StandardScaler().fit_transform(x_data)\n",
    "pca = PCA(n_components=10)\n",
    "scores = pca.fit_transform(center_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captured Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loadings - PC1 - Mostly independent, except temperature, which have same signs, meaning one temperature increases, the other ones increases, this response is modelled by sorting temperature from low to high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "x_loc = np.arange(1,len(pca.components_[0])+1)\n",
    "grouping = {'Reflux':slice(0,1),'Product':slice(1,7),'Temperature':slice(7,20),\\\n",
    "            'Catalyst':slice(20,33),'Feed':slice(33,None)}\n",
    "\n",
    "for key in grouping:\n",
    "    axs.bar(x_loc[grouping[key]],pca.components_[0][grouping[key]])\n",
    "axs.set_xticks([1,4.5,14,27,40])\n",
    "axs.set_xticklabels(list(grouping.keys()))\n",
    "\n",
    "axs.set_xlabel('Variable')\n",
    "axs.set_ylabel('Loading')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores - Success rate is not biased towards certain combination, uniform distributed set of initialized solutions for optimization multi-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "\n",
    "targets = ['Random Start', 'Initialization Complete', 'Optimized Any', 'Optimized All']\n",
    "colors = ['C1', 'C2', 'C3','C4']\n",
    "masks = {'Random Start':True,\\\n",
    "         'Initialization Complete':finished_initialization,\\\n",
    "         'Optimized Any':finished_optimization_any,\\\n",
    "         'Optimized All':finished_optimization_all}\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    mask = masks[target]\n",
    "    axs.scatter(scores[:,0][mask],scores[:,1][mask],color=color,label=target)\n",
    "\n",
    "axs.legend()\n",
    "axs.set_xlabel('Principal Component 1')\n",
    "axs.set_ylabel('Principal Component 2')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second, let's take a look at cause of failure and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization_failure_case\n",
    "# DDF_product_failure_case\n",
    "# revenue_failure_case\n",
    "# DDF_reflux_failure_case\n",
    "# profit_3_failure_case\n",
    "# profit_3_1_failure_case\n",
    "# profit_3_1_failure_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_cause_list = []\n",
    "\n",
    "for j in DDF_product_failure_case:\n",
    "    file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "    with open('./log/text/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "        for line in reversed(log_content):\n",
    "            if line.startswith('>') or 'Working on' in line:\n",
    "                break_cause = line.replace('> ','')\n",
    "                failure_cause_list.append(break_cause)\n",
    "                break\n",
    "\n",
    "# print(len(failure_cause_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine failure causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_short = []\n",
    "for line in failure_cause_list:\n",
    "    \n",
    "    if 'temperature' in line:\n",
    "        start = 'Working on adjusting '\n",
    "        end = 'temperature'\n",
    "        failure_short.append(line[line.find(start) + len(start) : line.rfind(end)] + 'Temp')\n",
    "    \n",
    "    elif 'changing Q' in line:\n",
    "        start = 'Working on '\n",
    "        end = ','\n",
    "        failure_short.append(line[line.find(start) + len(start) : line.rfind(end)] + ' duty')\n",
    "    \n",
    "    elif 'catalyst and feed' in line:\n",
    "        start = 'alpha = '\n",
    "        end = ':'\n",
    "        failure_short.append('alpha: ' + line[line.find(start) + len(start) : line.rfind(end)] + ' feed/catalyst')\n",
    "    \n",
    "    elif 'Reflux' in line:\n",
    "        start = 'PR ratio = '\n",
    "        end = '\\n'\n",
    "        failure_short.append('PR-ratio: '+ line[line.find(start) + len(start) : line.rfind(end)] + ' reflux')\n",
    "    \n",
    "    elif 'Connect' in line:\n",
    "        failure_short.append('stages 20 connect')\n",
    "        \n",
    "    elif 'DDF' in line:\n",
    "        failure_short.append('add 3 DDF')\n",
    "    \n",
    "    else:\n",
    "        failure_short.append(line.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_counts = Counter(failure_short)\n",
    "failure_counts = sorted(dict(failure_counts).items(),key=lambda x: (x[0].split(' ')[-1],float(x[0].split(' ')[1])),reverse=False)\n",
    "       \n",
    "failure_dic = {}\n",
    "for key, group in it.groupby(failure_counts,lambda pair: pair[0].split()[-1]):\n",
    "    failure_dic[key] = list(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(i[1] for i in failure_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "loc = 0\n",
    "names = []\n",
    "for key in failure_dic.keys():\n",
    "    frequencies = [j for i,j in failure_dic[key]]\n",
    "#     names += [i[:i.rfind(' ')] for i,j in failure_dic[key]]\n",
    "    \n",
    "    for i,j in failure_dic[key]:\n",
    "        if i == 'add 3 DDF':\n",
    "            names += ['DDF']\n",
    "        elif i == 'stages 20 connect':\n",
    "            names += ['connect']\n",
    "        else:\n",
    "            names += [i[:i.rfind(' ')]]\n",
    "\n",
    "    x_coordinates = np.arange(loc,len(failure_dic[key])+loc)\n",
    "    axs.bar(x_coordinates, frequencies, align='center',label = key)\n",
    "    loc += len(failure_dic[key])\n",
    "\n",
    "axs.set_xticks(np.arange(loc))\n",
    "axs.set_xticklabels(names,rotation=45,ha='right')\n",
    "\n",
    "axs.set_ylabel('Occurrences')\n",
    "axs.legend()\n",
    "axs.set_title('Causes of Failure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_fail_list = []\n",
    "profit_3_fail_list = []\n",
    "profit_3_1_fail_list = []\n",
    "profit_3_2_fail_list = []\n",
    "\n",
    "restoration_fail_case =[]\n",
    "\n",
    "for j in [j for j in revenue_failure_case if j not in DDF_product_failure_case]:\n",
    "    file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "    with open('./log/text/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "\n",
    "        for line in reversed(log_content):\n",
    "            if line.startswith('EXIT:'):\n",
    "                if 'Optimal Solution Found' in line:\n",
    "                    revenue_fail_list.append('Restoration Failed')\n",
    "                    restoration_fail_case.append(j)\n",
    "                else:\n",
    "                    revenue_fail_list.append(line.replace('EXIT: ','').replace('\\n',''))\n",
    "                break\n",
    "\n",
    "\n",
    "for j in [j for j in profit_3_failure_case if j not in DDF_reflux_failure_case]:\n",
    "    file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "    with open('./log/text/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "\n",
    "        for line in reversed(log_content):\n",
    "            if line.startswith('EXIT:'):\n",
    "                if 'Optimal Solution Found' in line:\n",
    "                    profit_3_fail_list.append('Maximum Number of Iterations Exceeded.')\n",
    "                else:\n",
    "                    profit_3_fail_list.append(line.replace('EXIT: ','').replace('\\n',''))\n",
    "                break\n",
    "\n",
    "        \n",
    "for j in [j for j in profit_3_1_failure_case if j not in DDF_reflux_failure_case]:\n",
    "    file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "    with open('./log/text/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "\n",
    "        for line in reversed(log_content):\n",
    "            if line.startswith('EXIT:'):\n",
    "                if 'Optimal Solution Found' in line:\n",
    "                    profit_3_1_fail_list.append('Maximum Number of Iterations Exceeded.')\n",
    "                else:\n",
    "                    profit_3_1_fail_list.append(line.replace('EXIT: ','').replace('\\n',''))\n",
    "                break\n",
    "\n",
    "\n",
    "for j in [j for j in profit_3_2_failure_case if j not in DDF_reflux_failure_case]:\n",
    "    file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "    with open('./log/text/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "\n",
    "        for line in reversed(log_content):\n",
    "            if line.startswith('EXIT:'):\n",
    "                if 'Optimal Solution Found' in line:\n",
    "                    profit_3_2_fail_list.append('Restoration Failed')\n",
    "                    restoration_fail_case.append(j)\n",
    "                else:\n",
    "                    profit_3_2_fail_list.append(line.replace('EXIT: ','').replace('\\n',''))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'Maximum Number of Iterations Exceeded.': 304,\n",
       "          'Restoration Failed': 11,\n",
       "          'Converged to a point of local infeasibility. Problem may be infeasible.': 1}),\n",
       " Counter({'Maximum Number of Iterations Exceeded.': 2}),\n",
       " Counter({'Maximum Number of Iterations Exceeded.': 14}),\n",
       " Counter({'Restoration Failed': 1,\n",
       "          'Maximum Number of Iterations Exceeded.': 11}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(revenue_fail_list), Counter(profit_3_fail_list), Counter(profit_3_1_fail_list), Counter(profit_3_2_fail_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # j_list = [603, 712]\n",
    "# j_list = [34, 47, 63, 133, 222, 251, 334, 383, 643, 832, 858, 915, 944, 988]\n",
    "# for case in j_list:\n",
    "#     file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(case)\n",
    "#     with open('./log/text/'+file_name) as f:\n",
    "#         log_content = f.readlines()\n",
    "\n",
    "#         for j, line in enumerate(reversed(log_content)):\n",
    "#             if '> One-step Optimization - Profit 3-1' in line:\n",
    "#                 print('case-{}: True'.format(case))\n",
    "#                 break\n",
    "#         print(log_content[-j+46])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lastly, optimization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_obj_list = []\n",
    "revenue_case_list = []\n",
    "revenue_opt_results = []\n",
    "revenue_opt_origin_results = []\n",
    "\n",
    "for j_,j in enumerate(total_runs):\n",
    "    if finished_revenue[j_]:\n",
    "        file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "        case = j\n",
    "        with open('./log/text/'+file_name) as f:\n",
    "            log_content = f.readlines()\n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "                # get the right position, i know it is bad coding, but dont want make too much changes to the old code\n",
    "                if '> One-step Optimization - Revenue' in line:\n",
    "                    starter_position = j - 50            \n",
    "            \n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "\n",
    "                if j <= starter_position:\n",
    "                    continue\n",
    "                \n",
    "                if line.startswith('obj'):\n",
    "                    start = 'obj '\n",
    "                    end = '\\n'\n",
    "                    string = line[line.find(start)+len(start):line.rfind(end)]\n",
    "                    string = string.strip()\n",
    "                    revenue_obj_list.append(float(string))\n",
    "                    revenue_case_list.append(case)\n",
    "                    break\n",
    "            \n",
    "            revenue_opt_results.append([log_content[-j+4]]+log_content[-j+14:-j+27]+log_content[-j+32:-j+37])\n",
    "            revenue_opt_origin_results.append([log_content[-j-47]]+log_content[-j-37:-j-24]+log_content[-j-19:-j-14])\n",
    "            \n",
    "revenue_opt_results = [[data.split() for data in case] for case in revenue_opt_results]\n",
    "revenue_opt_origin_results = [[data.split() for data in case] for case in revenue_opt_origin_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_obj_list = []\n",
    "profit_3_case_list = []\n",
    "profit_3_opt_results = []\n",
    "profit_3_opt_origin_results = []\n",
    "\n",
    "for j_,j in enumerate(total_runs):\n",
    "    if finished_profit_3[j_]:\n",
    "        file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "        case = j\n",
    "        with open('./log/text/'+file_name) as f:\n",
    "            log_content = f.readlines()\n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "                # get the right position, i know it is bad coding, but dont want make too much changes to the old code\n",
    "                if '> One-step Optimization - Profit 3' in line:\n",
    "                    starter_position = j - 50            \n",
    "            \n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "\n",
    "                if j <= starter_position:\n",
    "                    continue\n",
    "                \n",
    "                if line.startswith('obj'):\n",
    "                    start = 'obj '\n",
    "                    end = '\\n'\n",
    "                    string = line[line.find(start)+len(start):line.rfind(end)]\n",
    "                    string = string.strip()\n",
    "                    profit_3_obj_list.append(float(string))\n",
    "                    profit_3_case_list.append(case)\n",
    "                    break\n",
    "            profit_3_opt_results.append([log_content[-j+4]]+log_content[-j+14:-j+27]+log_content[-j+32:-j+39])\n",
    "            profit_3_opt_origin_results.append([log_content[-j-47]]+log_content[-j-37:-j-24]+log_content[-j-19:-j-14])\n",
    "            \n",
    "profit_3_opt_results = [[data.split() for data in case] for case in profit_3_opt_results]\n",
    "profit_3_opt_origin_results = [[data.split() for data in case] for case in profit_3_opt_origin_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_1_obj_list = []\n",
    "profit_3_1_case_list = []\n",
    "profit_3_1_opt_results = []\n",
    "profit_3_1_opt_origin_results = []\n",
    "\n",
    "for j_,j in enumerate(total_runs):\n",
    "    if finished_profit_3_1[j_]:\n",
    "        file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "        case = j\n",
    "        with open('./log/text/'+file_name) as f:\n",
    "            log_content = f.readlines()\n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "                # get the right position, i know it is bad coding, but dont want make too much changes to the old code\n",
    "                if '> One-step Optimization - Profit 3-1' in line:\n",
    "                    starter_position = j - 50            \n",
    "            \n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "\n",
    "                if j <= starter_position:\n",
    "                    continue\n",
    "                \n",
    "                if line.startswith('obj'):\n",
    "                    start = 'obj '\n",
    "                    end = '\\n'\n",
    "                    string = line[line.find(start)+len(start):line.rfind(end)]\n",
    "                    string = string.strip()\n",
    "                    profit_3_1_obj_list.append(float(string))\n",
    "                    profit_3_1_case_list.append(case)\n",
    "                    break\n",
    "            profit_3_1_opt_results.append([log_content[-j+4]]+log_content[-j+14:-j+27]+log_content[-j+32:-j+39])\n",
    "            profit_3_1_opt_origin_results.append([log_content[-j-100]]+log_content[-j-90:-j-77]+log_content[-j-72:-j-67])\n",
    "\n",
    "            \n",
    "profit_3_1_opt_results = [[data.split() for data in case] for case in profit_3_1_opt_results]\n",
    "profit_3_1_opt_origin_results = [[data.split() for data in case] for case in profit_3_1_opt_origin_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_2_obj_list = []\n",
    "profit_3_2_case_list = []\n",
    "profit_3_2_opt_results = []\n",
    "profit_3_2_opt_origin_results = []\n",
    "\n",
    "for j_,j in enumerate(total_runs):\n",
    "    if finished_profit_3_2[j_]:\n",
    "        file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "        case = j\n",
    "        with open('./log/text/'+file_name) as f:\n",
    "            log_content = f.readlines()\n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "                # get the right position, i know it is bad coding, but dont want make too much changes to the old code\n",
    "                if '> One-step Optimization - Profit 3-2' in line:\n",
    "                    starter_position = j - 50            \n",
    "            \n",
    "            \n",
    "            for j, line in enumerate(reversed(log_content)):\n",
    "\n",
    "                if j <= starter_position:\n",
    "                    continue\n",
    "                \n",
    "                if line.startswith('obj'):\n",
    "                    start = 'obj '\n",
    "                    end = '\\n'\n",
    "                    string = line[line.find(start)+len(start):line.rfind(end)]\n",
    "                    string = string.strip()\n",
    "                    profit_3_2_obj_list.append(float(string))\n",
    "                    profit_3_2_case_list.append(case)\n",
    "                    break\n",
    "            profit_3_2_opt_results.append([log_content[-j+4]]+log_content[-j+14:-j+27]+log_content[-j+32:-j+37])\n",
    "            profit_3_2_opt_origin_results.append([log_content[-j-153]]+log_content[-j-143:-j-130]+log_content[-j-125:-j-120])\n",
    "\n",
    "profit_3_2_opt_results = [[data.split() for data in case] for case in profit_3_2_opt_results]\n",
    "profit_3_2_opt_origin_results = [[data.split() for data in case] for case in profit_3_2_opt_origin_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_case_list[np.argmax(revenue_obj_list)], max(revenue_obj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_case_list[np.argmax(profit_3_obj_list)], max(profit_3_obj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_1_case_list[np.argmax(profit_3_1_obj_list)], max(profit_3_1_obj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_2_case_list[np.argmax(profit_3_2_obj_list)], max(profit_3_2_obj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "y, bins, patches = axs.hist(revenue_obj_list,bins=50,histtype='bar',alpha=0.7)\n",
    "axs.set_title('Obj - revenue')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "y, bins, patches = axs.hist(profit_3_obj_list,bins=50,histtype='bar',alpha=0.7)\n",
    "axs.set_title('Obj - profit-3')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "y, bins, patches = axs.hist(profit_3_1_obj_list,bins=50,histtype='bar',alpha=0.7)\n",
    "axs.set_title('Obj - profit-3-1')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "y, bins, patches = axs.hist(profit_3_2_obj_list,bins=50,histtype='bar',alpha=0.7)\n",
    "axs.set_title('Obj - profit-3-2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization result: obj-revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_opt_results_matrix = np.stack((\n",
    "    [float(case[0][-3])/float(case[0][-2]) for case in revenue_opt_results],\n",
    "    [float(case[-1][-1]) for case in revenue_opt_results], # intermediate location\n",
    "    [float(case[-1][-8]) for case in revenue_opt_results], # intermediate draw\n",
    "    [float(case[-4][-1]) for case in revenue_opt_results], # gasoline location\n",
    "    [float(case[-4][-8]) for case in revenue_opt_results], # gasoline draw\n",
    "    [float(case[-3][-1]) for case in revenue_opt_results], # diesel location\n",
    "    [float(case[-3][-8]) for case in revenue_opt_results], # diesel draw\n",
    "#     [float(case[-5][-8]) for case in revenue_opt_results], # naphtha draw\n",
    "#     [float(case[-2][-8]) for case in revenue_opt_results], # heavy draw\n",
    "    *np.array([[float(obv[1]) for obv in case[1:14]] for case in revenue_opt_results]).T,\n",
    "    *np.array([[float(obv[6]) for obv in case[1:14]] for case in revenue_opt_results]).T,\n",
    "    *np.array([[float(obv[5]) for obv in case[1:14]] for case in revenue_opt_results]).T,\n",
    "    [obj for obj in revenue_obj_list]\n",
    "),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_opt_origin_matrix = np.stack((\n",
    "    [float(case[0][-3])/float(case[0][-2]) for case in revenue_opt_origin_results],\n",
    "    [float(case[-1][-1]) for case in revenue_opt_origin_results], # intermediate location\n",
    "    [float(case[-1][-8]) for case in revenue_opt_origin_results], # intermediate draw\n",
    "    [float(case[-4][-1]) for case in revenue_opt_origin_results], # gasoline location\n",
    "    [float(case[-4][-8]) for case in revenue_opt_origin_results], # gasoline draw\n",
    "    [float(case[-3][-1]) for case in revenue_opt_origin_results], # diesel location\n",
    "    [float(case[-3][-8]) for case in revenue_opt_origin_results], # diesel draw\n",
    "#     [float(case[-5][-8]) for case in revenue_opt_origin_results], # naphtha draw\n",
    "#     [float(case[-2][-8]) for case in revenue_opt_origin_results], # heavy draw\n",
    "    *np.array([[float(obv[1]) for obv in case[1:14]] for case in revenue_opt_origin_results]).T,\n",
    "    *np.array([[float(obv[6]) for obv in case[1:14]] for case in revenue_opt_origin_results]).T,\n",
    "    *np.array([[float(obv[5]) for obv in case[1:14]] for case in revenue_opt_origin_results]).T,\n",
    "    [obj for obj in revenue_obj_list]\n",
    "),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_opt_results_unique_unsorted, revenue_unique_index, revenue_unique_counts = \\\n",
    "np.unique(revenue_opt_results_matrix,axis=0,return_index=True,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_unique_global_index = [np.array(total_runs)[finished_revenue][j] for j in revenue_unique_index]\n",
    "revenue_opt_results_unique = np.array(sorted(revenue_opt_results_unique_unsorted,key=lambda x: x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.precision = 4\n",
    "pd.DataFrame(sorted([i for i in zip(revenue_opt_results_unique_unsorted[:,-1],revenue_unique_counts,revenue_unique_global_index)],\\\n",
    "                    key=lambda x: x[0]),columns=['Objective Value','Occurances','Example Index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.expand_frame_repr = False\n",
    "pd.options.display.max_colwidth = 80000\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.precision = 0\n",
    "pd.DataFrame(revenue_opt_results_unique[::4,7:20].T,index=['Tem{}'.format(j) for j in range(8,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.precision = 0\n",
    "pd.DataFrame(revenue_opt_results_unique[::4,20:33].T,index=['Catalyst {}'.format(j) for j in range(8,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.precision = 2\n",
    "pd.DataFrame(revenue_opt_results_unique[::4,33:-1].T,index=['Feed {}'.format(j) for j in range(8,21)]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_scaled = StandardScaler().fit_transform(revenue_opt_results_unique[::4,:-1])\n",
    "pca = PCA(n_components=10)\n",
    "scores = pca.fit_transform(center_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captured Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_ratio_[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrolation between PC1 and optimized objective value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(16,9))\n",
    "\n",
    "'''\n",
    "Scores\n",
    "'''\n",
    "x_loc = np.arange(1,len(scores[:,0])+1)\n",
    "axs[0].bar(x_loc,scores[:,1],color = 'C1')\n",
    "\n",
    "axs_ = axs[0].twinx()\n",
    "axs_.plot(x_loc,revenue_opt_results_unique[::4,-1],'C2:o',markeredgecolor='w',markeredgewidth = 1,markersize=12)\n",
    "\n",
    "\n",
    "\n",
    "# axs[1].legend()\n",
    "axs[0].set_xlabel('Local Minimums')\n",
    "axs[0].set_ylabel('Score - PC1')\n",
    "axs_.set_ylabel('Revenue')\n",
    "\n",
    "'''\n",
    "Loading\n",
    "'''\n",
    "x_loc = np.arange(1,len(pca.components_[0])+1)\n",
    "grouping = {'Reflux':slice(0,1),'Product':slice(1,7),'Temperature':slice(7,20),\\\n",
    "            'Catalyst':slice(20,33),'Feed':slice(33,None)}\n",
    "\n",
    "for key in grouping:\n",
    "    axs[1].bar(x_loc[grouping[key]],pca.components_[0][grouping[key]])\n",
    "axs[1].set_xticks([1,4.5,14,27,40])\n",
    "axs[1].set_xticklabels(list(grouping.keys()))\n",
    "\n",
    "axs[1].set_ylabel('Loading - PC1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using pre-optimization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_opt_origin_scaled = StandardScaler().fit_transform(revenue_opt_origin_matrix[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_scores = pca.transform(revenue_opt_origin_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "\n",
    "targets = ['Bad','Middle','Good','Super']\n",
    "colors = ['C1', 'C2','C3','C4']\n",
    "masks = {'Bad':[[0,21.54],slice(0,10),80],\\\n",
    "         'Middle':[[21.55,21.80],slice(10,20),10],\\\n",
    "         'Good':[[21.81,22.07],slice(20,60),10],\\\n",
    "         'Super':[[22.08,22.33],slice(60,87),80]}\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    mask = masks[target]\n",
    "    axs.scatter(scores[:,0][mask[1]],scores[:,1][mask[1]],color=color,label=target)\n",
    "    tmp = [j for j,run in enumerate(revenue_opt_results_matrix) if run[-1] >= mask[0][0] and run[-1] <= mask[0][1]]\n",
    "\n",
    "axs.legend()\n",
    "axs.set_xlabel('Principal Component 1')\n",
    "axs.set_ylabel('Principal Component 2')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating between \"Middle\" and \"Good\" will involve 3rd and 4th component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16,9))\n",
    "\n",
    "targets = ['Middle','Good']\n",
    "colors = ['C2','C3']\n",
    "masks = {'Middle':[[21.55,21.80],slice(20,60),20],\\\n",
    "         'Good':[[21.81,22.07],slice(60,87),20]}\n",
    "\n",
    "for target, color in zip(targets,colors):\n",
    "    mask = masks[target]\n",
    "    axs.scatter(scores[:,2][mask[1]],scores[:,3][mask[1]],color=color,label=target)\n",
    "    tmp = [j for j,run in enumerate(revenue_opt_results_matrix) if run[-1] >= mask[0][0] and run[-1] <= mask[0][1]]\n",
    "\n",
    "axs.legend()\n",
    "axs.set_xlabel('Principal Component 3')\n",
    "axs.set_ylabel('Principal Component 4')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization results: profit-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 80\n",
    "pd.options.display.max_rows = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_opt_results_matrix = np.stack((\n",
    "    [float(case[0][-3])/float(case[0][-2]) for case in profit_3_opt_results],\n",
    "    [float(case[-3][-1]) for case in profit_3_opt_results], # intermediate location\n",
    "    [float(case[-3][-8]) for case in profit_3_opt_results], # intermediate draw\n",
    "    [float(case[-6][-1]) for case in profit_3_opt_results], # gasoline location\n",
    "    [float(case[-6][-8]) for case in profit_3_opt_results], # gasoline draw\n",
    "    [float(case[-5][-1]) for case in profit_3_opt_results], # diesel location\n",
    "    [float(case[-5][-8]) for case in profit_3_opt_results], # diesel draw\n",
    "#     [float(case[-7][-8]) for case in profit_3_opt_results], # naphtha draw\n",
    "#     [float(case[-4][-8]) for case in profit_3_opt_results], # heavy draw\n",
    "    *np.array([[float(obv[1]) for obv in case[1:14]] for case in profit_3_opt_results]).T, # Temperature\n",
    "    *np.array([[float(obv[6]) for obv in case[1:14]] for case in profit_3_opt_results]).T, # Catalyst\n",
    "    *np.array([[float(obv[5]) for obv in case[1:14]] for case in profit_3_opt_results]).T, # Feed\n",
    "    [float(case[-2][-1]) for case in profit_3_opt_results], # Reflux tray\n",
    "    [float(case[-1][-1]) for case in profit_3_opt_results], # Total feed\n",
    "    [obj for obj in profit_3_obj_list]\n",
    "),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_opt_origin_matrix = np.stack((\n",
    "    [float(case[0][-3])/float(case[0][-2]) for case in profit_3_opt_origin_results],\n",
    "    [float(case[-1][-1]) for case in profit_3_opt_origin_results], # intermediate location\n",
    "    [float(case[-1][-8]) for case in profit_3_opt_origin_results], # intermediate draw\n",
    "    [float(case[-4][-1]) for case in profit_3_opt_origin_results], # gasoline location\n",
    "    [float(case[-4][-8]) for case in profit_3_opt_origin_results], # gasoline draw\n",
    "    [float(case[-3][-1]) for case in profit_3_opt_origin_results], # diesel location\n",
    "    [float(case[-3][-8]) for case in profit_3_opt_origin_results], # diesel draw\n",
    "#     [float(case[-5][-8]) for case in profit_3_opt_origin_results], # naphtha draw\n",
    "#     [float(case[-2][-8]) for case in profit_3_opt_origin_results], # heavy draw\n",
    "    *np.array([[float(obv[1]) for obv in case[1:14]] for case in profit_3_opt_origin_results]).T, # Temperature\n",
    "    *np.array([[float(obv[6]) for obv in case[1:14]] for case in profit_3_opt_origin_results]).T, # Catalyst\n",
    "    *np.array([[float(obv[5]) for obv in case[1:14]] for case in profit_3_opt_origin_results]).T, # Feed\n",
    "    [obj for obj in profit_3_obj_list]\n",
    "),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_opt_results_unique_unsorted, profit_3_unique_index, profit_3_unique_counts = np.unique(profit_3_opt_results_matrix,axis=0,return_index=True,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_3_unique_global_index = [np.array(total_runs)[finished_profit_3][j] for j in profit_3_unique_index]\n",
    "profit_3_opt_results_unique = np.array(sorted(profit_3_opt_results_unique_unsorted,key=lambda x: x[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.precision = 4\n",
    "pd.DataFrame(sorted([i for i in zip(profit_3_opt_results_unique_unsorted[:,-1],profit_3_unique_counts,profit_3_unique_global_index)],\\\n",
    "                    key=lambda x: x[0]),columns=['Objective Value','Occurances','Example Index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.expand_frame_repr = False\n",
    "pd.options.display.max_colwidth = 80000\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.precision = 0\n",
    "pd.DataFrame(profit_3_opt_results_unique[::4,7:20].T,index=['Tem{}'.format(j) for j in range(8,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.precision = 0\n",
    "pd.DataFrame(profit_3_opt_results_unique[::4,20:33].T,index=['Catalyst {}'.format(j) for j in range(8,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.precision = 2\n",
    "pd.DataFrame(profit_3_opt_results_unique[::4,33:-3].T,index=['Feed {}'.format(j) for j in range(8,21)]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_scaled = StandardScaler().fit_transform(profit_3_opt_results_unique[::4,:-1])\n",
    "pca = PCA(n_components=10)\n",
    "scores = pca.fit_transform(center_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captured Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_ratio_[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrolation between PC1 and optimized objective value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(16,9))\n",
    "\n",
    "'''\n",
    "Scores\n",
    "'''\n",
    "x_loc = np.arange(1,len(scores[:,0])+1)\n",
    "axs[0].bar(x_loc,scores[:,0],color = 'C1')\n",
    "\n",
    "axs_ = axs[0].twinx()\n",
    "axs_.plot(x_loc,profit_3_opt_results_unique[::4,-1],'C2:o',markeredgecolor='w',markeredgewidth = 1,markersize=12)\n",
    "\n",
    "# axs[1].legend()\n",
    "axs[0].set_xlabel('Local Minimums')\n",
    "axs[0].set_ylabel('Score - PC1')\n",
    "axs_.set_ylabel('Profit-3')\n",
    "\n",
    "'''\n",
    "Loading\n",
    "'''\n",
    "x_loc = np.arange(1,len(pca.components_[0])+1)\n",
    "grouping = {'Reflux':slice(0,1),'Product':slice(1,7),'Temperature':slice(7,20),\\\n",
    "            'Catalyst':slice(20,33),'Feed':slice(33,46),'R-Tray':slice(46,47),'T-Feed':slice(47,48)}\n",
    "\n",
    "for key in grouping:\n",
    "    axs[1].bar(x_loc[grouping[key]],pca.components_[0][grouping[key]])\n",
    "axs[1].set_xticks([1,4.5,14,27,40,47,48])\n",
    "axs[1].set_xticklabels(list(grouping.keys()))\n",
    "\n",
    "axs[1].set_ylabel('Loading - PC1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Temp Comparison: Sucess vs Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_failure_case_ = [case for case in revenue_failure_case if case not in DDF_product_failure_case]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_success_case_ = [total_runs[j_] for j_, j in enumerate(finished_revenue) if j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_temp_revenue_failure = []\n",
    "\n",
    "for j in revenue_failure_case_:\n",
    "    file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "    with open('./log/text/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "            \n",
    "        for j, line in enumerate(reversed(log_content)):\n",
    "            if '> Added DDF formulation - Product' in line:\n",
    "                break\n",
    "        initial_temp_revenue_failure.append(log_content[-j+15:-j+28])\n",
    "            \n",
    "initial_temp_revenue_failure = [[data.split() for data in case] for case in initial_temp_revenue_failure]\n",
    "initial_temp_revenue_failure = np.array([[float(obv[1]) for obv in case] for case in initial_temp_revenue_failure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_temp_revenue_success = []\n",
    "\n",
    "for j in revenue_success_case_:\n",
    "    file_name = 'mul_onestep_Preset_Case_{}_pf.dat'.format(j)\n",
    "    with open('./log/text/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "            \n",
    "        for j, line in enumerate(reversed(log_content)):\n",
    "            if '> Added DDF formulation - Product' in line:\n",
    "                break\n",
    "        initial_temp_revenue_success.append(log_content[-j+15:-j+28])\n",
    "            \n",
    "initial_temp_revenue_success = [[data.split() for data in case] for case in initial_temp_revenue_success]\n",
    "initial_temp_revenue_success = np.array([[float(obv[1]) for obv in case] for case in initial_temp_revenue_success])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_temp_revenue_failure = np.mean(initial_temp_revenue_failure, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_temp_revenue_success = np.mean(initial_temp_revenue_success, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_temp_revenue_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_temp_revenue_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoration Fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74, 124, 168, 233, 263, 419, 453, 459, 552, 778, 782, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restoration_fail_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "restoration_phase = []\n",
    "restoration_phase_case = []\n",
    "\n",
    "for j in restoration_fail_case:\n",
    "    file_name = 'Preset_Case_{}_pf.output'.format(j)\n",
    "    case = j\n",
    "    with open('./tmp/'+file_name) as f:\n",
    "        log_content = f.readlines()\n",
    "            \n",
    "        for j, line in enumerate(reversed(log_content)):\n",
    "            if line.startswith('Number of Iterations....'):\n",
    "                break\n",
    "        if j < 50:\n",
    "            restoration_phase.append(log_content[-j+2:-j+4])\n",
    "            restoration_phase_case.append(case)\n",
    "            \n",
    "restoration_phase = [[data.split() for data in case] for case in restoration_phase]\n",
    "restoration_phase_obj = np.array([[float(obv[1]) for obv in case[0:1]] for case in restoration_phase])\n",
    "restoration_phase_inf = np.array([[float(obv[2]) for obv in case[1:2]] for case in restoration_phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case:\t124\t\t-17.27\t\t9.90e+12\n",
      "case:\t168\t\t-24.26\t\t1.72e+16\n",
      "case:\t419\t\t-0.01\t\t1.33e+17\n",
      "case:\t453\t\t-10.69\t\t1.00e+02\n",
      "case:\t459\t\t4.51\t\t8.97e+16\n",
      "case:\t552\t\t3.58\t\t1.01e+02\n",
      "case:\t778\t\t-16.54\t\t5.33e+07\n",
      "case:\t782\t\t8.03\t\t2.49e+16\n",
      "case:\t1\t\t-4.51\t\t9.01e+07\n"
     ]
    }
   ],
   "source": [
    "for case,i,j in zip(restoration_phase_case,restoration_phase_obj, restoration_phase_inf):\n",
    "    print('case:\\t{}\\t\\t{:2.2f}\\t\\t{:.2e}'.format(case,i[0],j[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
